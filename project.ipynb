{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from charset_normalizer import from_path\n",
    "from nltk import tokenize, stem, corpus, download\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre code on utilise deux fichier, un fichier \"spam.txt\" qui contient tout les chemins vers les fichiers spam, et un fichier \"ham.txt\" qui contient tout les chemins vers les fichiers ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction de nettoyage des mails et d'extractions de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path):\n",
    "    \n",
    "    keywordsReg = r\"^\\s*(To:|From:|Subject:|Date:|Content\\W(.*?):)\" #Regex mot cles d'un email (subjec, to, from ...etc)\n",
    "    HTMLreg = r\"<(.|\\n)+?>\" #Regex balise HTML\n",
    "    adressReg = r\"\\b[\\w-]+@[\\w-]+\\.[A-Za-z]\\b\" #Regex adress email\n",
    "    urlReg = r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\" #Regex URL\n",
    "\n",
    "    i = 0\n",
    "    tokensList = []\n",
    "    fileName = path.split('/')[-1][:-1]\n",
    "    encoding = from_path(path[:-1]).best().encoding\n",
    "    spamMail = open(path[:-1], \"r\", encoding=encoding)\n",
    "    \n",
    "    content = \"\"\n",
    "    while(spamMail.readline() != '\\n'):\n",
    "        pass\n",
    "\n",
    "    for line in spamMail.readlines():\n",
    "        if re.search(keywordsReg, line) == None:\n",
    "            content = content + line\n",
    "    \n",
    "    content = re.sub(HTMLreg, \" \", content)\n",
    "    content = re.sub(adressReg, \" emailaddr \", content)\n",
    "    content = re.sub(urlReg, \" httpaddr \", content)\n",
    "    content = re.sub(r\"\\d+\", \" number \" , content)\n",
    "    content = re.sub(r\"$\", \" dollar \", content)\n",
    "    content = content.lower()\n",
    "\n",
    "    spamMail.close()\n",
    "\n",
    "    tokenizer = tokenize.TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(content)\n",
    "\n",
    "    stemmer = stem.SnowballStemmer(\"english\")\n",
    "    tokens = [stemmer.stem(token) for token in tokens if token.isalpha()]\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction des tokens des mails spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamPaths = open(\"spam.txt\", \"r\")\n",
    "spamTokens = []\n",
    "for path in spamPaths.readlines():\n",
    "    spamTokens = spamTokens + preprocess(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633208\n"
     ]
    }
   ],
   "source": [
    "print(len(spamTokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction des tokens des mails ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamPaths = open(\"ham.txt\", \"r\")\n",
    "hamTokens = []\n",
    "\n",
    "for path in hamPaths.readlines() :\n",
    "    hamTokens = hamTokens + preprocess(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488616\n"
     ]
    }
   ],
   "source": [
    "print(len(hamTokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction du vocabulaire.\n",
    "On garde les tokens qui ont au moins K occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tokens total:  1121824\n",
      "Nombre de tokens sans stopwords:  739353\n",
      "Nombre de token dans le vocabulaire final:  5294\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "initial_vocab = hamTokens + spamTokens\n",
    "print('Nombre de tokens total: ' ,len(initial_vocab))\n",
    "\n",
    "download('stopwords', quiet=True)\n",
    "stopwords = corpus.stopwords.words('english')\n",
    "initial_vocab = [token for token in initial_vocab if token not in stopwords]\n",
    "print('Nombre de tokens sans stopwords: ' ,len(initial_vocab))\n",
    "\n",
    "final_vocab = [] \n",
    "k = 10 #nombre d'occurence minimum d'un token pour qu'il fait partie du vocabulaire\n",
    "frequencies = Counter(initial_vocab)\n",
    "for key,value in frequencies.items():\n",
    "    if value >= k:\n",
    "        final_vocab.append(key)\n",
    "\n",
    "print(\"Nombre de token dans le vocabulaire final: \", len(final_vocab))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction de la liste d'index de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_index = dict()\n",
    "i = 0 \n",
    "for i in range(len(final_vocab)):\n",
    "    token_to_index[final_vocab[i]] = i "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation des mail en séquence d'index de mot du vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(path):\n",
    "    tokens = preprocess(path)\n",
    "    transformed = [token_to_index[token] for token in tokens if token in final_vocab]\n",
    "    return transformed\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction des caractéristiques par comptage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counterFeatures(path):\n",
    "    indices = transform(path)\n",
    "    X = np.zeros((1,len(final_vocab)))\n",
    "\n",
    "    for i in indices:\n",
    "        X[0][i] += 1 \n",
    "\n",
    "    return X \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction du DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamPaths.seek(0)\n",
    "hamPaths.seek(0)\n",
    "paths = spamPaths.readlines() + hamPaths.readlines()\n",
    "\n",
    "n = len(final_vocab)\n",
    "m = len(paths)\n",
    "X_counter = np.zeros((m, n))\n",
    "for i in range(m) :\n",
    "    X_counter[i][:] = counterFeatures(paths[i]) \n",
    "\n",
    "X_binary = np.copy(X_counter)\n",
    "X_binary[X_binary > 1] = 1 ##Extraction des caracteristiques binaires\n",
    "\n",
    "\n",
    "Y = np.concatenate((np.ones((1396, 1)), np.zeros((2500, 1)))) #1396 email spam, 2500 non spam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparer les données en un ensemble d’entraînement et un ensemble d'evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_counter_train, X_counter_test, Y_counter_train, Y_counter_test = train_test_split(X_counter, Y, test_size=0.25) \n",
    "X_binary_train, X_binary_test, Y_binary_train, Y_binary_test = train_test_split(X_binary, Y, test_size=0.25) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche caractéristiques par comptage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_counter = SVC(C=0.1,kernel =\"linear\")\n",
    "svc_counter.fit(X_counter_train, Y_counter_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SVM Avec caracteristiques par comptages-----------------\n",
      "Training Accuracy: 99.7946611909651 %\n",
      "Testing Accuracy: 98.4599589322382 %\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------SVM Avec caracteristiques par comptages-----------------\")\n",
    "print(\"Training Accuracy:\",(svc_counter.score(X_counter_train, Y_counter_train.ravel()))*100,\"%\")\n",
    "print(\"Testing Accuracy:\",(svc_counter.score(X_counter_test, Y_counter_test.ravel()))*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche caractéristiques binaires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_binary = SVC(C=0.1,kernel =\"linear\")\n",
    "svc_binary.fit(X_binary_train, Y_binary_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SVM Avec caracteristiques binaires-----------------\n",
      "Training Accuracy: 99.69199178644764 %\n",
      "Testing Accuracy: 98.76796714579056 %\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------SVM Avec caracteristiques binaires-----------------\")\n",
    "print(\"Training Accuracy:\",(svc_binary.score(X_binary_train, Y_binary_train.ravel()))*100,\"%\")\n",
    "print(\"Testing Accuracy:\",(svc_binary.score(X_binary_test, Y_binary_test.ravel()))*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche caractéristiques par comptage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "bayes_counter = MultinomialNB()\n",
    "bayes_counter.fit(X_counter_train, Y_counter_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Naive Bayes Avec caracteristiques par comptages-----------------\n",
      "Training Accuracy: 95.24298425735797 %\n",
      "Testing Accuracy: 95.27720739219713 %\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Naive Bayes Avec caracteristiques par comptages-----------------\")\n",
    "print(\"Training Accuracy:\",(bayes_counter.score(X_counter_train, Y_counter_train.ravel()))*100,\"%\")\n",
    "print(\"Testing Accuracy:\",(bayes_counter.score(X_counter_test, Y_counter_test.ravel()))*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche caractéristiques binaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "bayes_binary = MultinomialNB()\n",
    "bayes_binary.fit(X_binary_train, Y_binary_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Naive Bayes Avec caracteristiques binaires-----------------\n",
      "Training Accuracy: 98.97330595482546 %\n",
      "Testing Accuracy: 98.35728952772074 %\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Naive Bayes Avec caracteristiques binaires-----------------\")\n",
    "print(\"Training Accuracy:\",(bayes_binary.score(X_binary_train, Y_binary_train.ravel()))*100,\"%\")\n",
    "print(\"Testing Accuracy:\",(bayes_binary.score(X_binary_test, Y_binary_test.ravel()))*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche caractéristiques par comptage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(50, 25))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_counter = MLPClassifier(hidden_layer_sizes=(50,25), activation = 'logistic')\n",
    "mlp_counter.fit(X_counter_train, Y_counter_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Reseau de neurones Avec caracteristiques par comptages-----------------\n",
      "Training Accuracy: 99.96577686516085 %\n",
      "Testing Accuracy: 98.4599589322382 %\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Reseau de neurones Avec caracteristiques par comptages-----------------\")\n",
    "print(\"Training Accuracy:\",(mlp_counter.score(X_counter_train, Y_counter_train.ravel()))*100,\"%\")\n",
    "print(\"Testing Accuracy:\",(mlp_counter.score(X_counter_test, Y_counter_test.ravel()))*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche caractéristiques binaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(50, 25))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_binary = MLPClassifier(hidden_layer_sizes=(50,25), activation = 'logistic')\n",
    "mlp_binary.fit(X_counter_train, Y_counter_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Naive Bayes Avec caracteristiques binaires-----------------\n",
      "Training Accuracy: 97.98083504449008 %\n",
      "Testing Accuracy: 98.04928131416838 %\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Naive Bayes Avec caracteristiques binaires-----------------\")\n",
    "print(\"Training Accuracy:\",(mlp_binary.score(X_binary_train, Y_binary_train.ravel()))*100,\"%\")\n",
    "print(\"Testing Accuracy:\",(mlp_binary.score(X_binary_test, Y_binary_test.ravel()))*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
