{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28616933",
   "metadata": {},
   "source": [
    "# Rapport du projet IARN - Classification Spam/Ham\n",
    "\n",
    "## Outils et librairies\n",
    "\n",
    "Nous utilisons pour dans ce projet les librairies suivantes :\n",
    "\n",
    "- **NLTK** : Librairie de traitement de langage. Utilisée pour la tokenisation des emails, l’élimination des mots vides (stopwords), et la radicalisation des mots.\n",
    "\n",
    "- **Scikit-learn** : Librairie d'algorithmes d'apprentissage machine.\n",
    "\n",
    "- **charset_normalizer** : Bibliothèque qui aide à lire du texte à partir d'un fichier dotant d'un encodage de jeu de caractères inconnu.\n",
    "\n",
    "## Préparation des données\n",
    "\n",
    "Les les fichiers qui contiennent des mails spam se trouve dans un dossier \"spam_2\", et les fichiers qui contiennent des mails non spam se trouve dans un dossier \"easy_ham\". on dispose de deux fichier \"spam.txt\" et \"ham.txt\", qui contiennent respectivement les chemins vers les mails spam et les chemins vers les mails non spam.\n",
    "\n",
    "On ouvre chaque fichier avec l'encodage qui lui convient à l'aide de charset_normalizer, puis on applique les transformations nécessaires pour obtenir un ensemble de tokens.\n",
    "\n",
    "### Construction du vocabulaire\n",
    "\n",
    "Tous les tokens des différents fichiers sont concaténés dans une seul list, on fait par la suite le compte des occurrences de chaque token et on ne garde que les tokens qui ont au moins $k$ nombres d'occurrences. On associe à chaque token un entier entre 0 et $n$, $n$ étant la taille de notre vocabulaire.\n",
    "\n",
    "Dans notre exemple on a pris $k = 10$, ce qui nous donne $n = 5294$.\n",
    "\n",
    "## Implémentation des modèle\n",
    "\n",
    "Dans ce travail, nous avons utilisé 3 modèles différents que nous présentons par la suite. Nous avons aussi testé ces algorithmes avec les deux encodages; vecteur binaire et vecteur de compteurs.\n",
    "\n",
    "### Modèles d'apprentissage machine\n",
    "\n",
    "#### Naive Bayes\n",
    "\n",
    "Pour cette algorithme, nous utilisons la formule multinomiale qui est plus adaptée que la forme gaussienne comme c'est un problème de nature discrète.\n",
    "\n",
    "On entraîne ce modèle avec les deux représentations vectorielles; binaire et à compteurs.\n",
    "\n",
    "#### SVM\n",
    "\n",
    "On utilise un SVM avec un noyau linéaire, car on dispose déjà d'assez de caractéristique.\n",
    "\n",
    "Et on prend le degré de tolérance C égale à 0.01 car les problèmes de classification de texte sont généralement linéairement séparables.\n",
    "\n",
    "On entraîne ce modèle avec les deux représentations vectorielles; binaire et à compteurs.\n",
    "\n",
    "#### Réseau de neurones\n",
    "On utilise un Réseau de neurones avec une première couche cachée de 50 neurones, et une deuxième couche cachée de 25 neurones.\n",
    "\n",
    "On entraîne ce modèle avec les deux représentations vectorielles; binaire et à compteurs.\n",
    "\n",
    "## Analyse des résultats\n",
    "\n",
    "Le tableau suivant contient les résultats des précisions calculés sur l'ensemble de test pour chaque algorithme :\n",
    "\n",
    "| Modèle   | RN          | Naive Bayes | SVM         |\n",
    "|----------|-------------|-------------|-------------|\n",
    "| Accuracy | 98.04%      | 98.35%      | 98.76%      |\n",
    "\n",
    "En utilisant la représentation vectorielle à compteurs nous ne trouvons pas de grande differences :\n",
    "\n",
    "| Modèle   | RN          | Naive Bayes | SVM         |\n",
    "|----------|-------------|-------------|-------------|\n",
    "| Accuracy | 98.45%      | 95.27%      | 98.45%      |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
